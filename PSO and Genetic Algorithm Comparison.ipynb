{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa667418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from Helper.Preprocessing import *\n",
    "from Helper.Model import *\n",
    "from Helper.GeneticAlgorithm import GeneticAlgorithm\n",
    "from Helper.PSO import PSO\n",
    "from Helper.FileManager import FileManager\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "sns.set(rc = {'figure.figsize':(20,8)})\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Activation\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a927533",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = pd.read_csv(\"../ufjf_dataset.csv\")\n",
    "dfx['timestamp'] = pd.to_datetime(dfx['timestamp'])\n",
    "dfx.index = dfx['timestamp']\n",
    "dfx['access_point'] = dfx['access_point'].str.lower()\n",
    "dfx.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ccc33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfx.access_point.unique()))\n",
    "print(len(dfx.host.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d8a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxx = dfx[dfx['access_point'].str.contains('ru')]\n",
    "l_ru = list(dfxx['access_point'].unique())\n",
    "#l_ru.remove('deptconstrucaocivilsala4107')\n",
    "print(l_ru)\n",
    "\n",
    "df = dfx[dfx['access_point'].str.contains('|'.join(l_ru))]\n",
    "\n",
    "X, Y = Preprocessing(df).get_data()\n",
    "max(Preprocessing(df).get_dataframe()['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1348831d",
   "metadata": {},
   "source": [
    "# Common Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853a2473",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation = 5\n",
    "population_size = 5\n",
    "P = 11\n",
    "Q = 3\n",
    "metric = 'r2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1547a3c8",
   "metadata": {},
   "source": [
    "# MLP Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff46ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_MAX = 200\n",
    "n_MIN = 20\n",
    "learning_rate_MAX = 0.0009\n",
    "learning_rate_MIN = 0.00001\n",
    "maxiter = 2000\n",
    "\n",
    "boundaries = np.zeros([2,2])\n",
    "boundaries[0,0] = n_MIN\n",
    "boundaries[1,0] = n_MAX\n",
    "boundaries[0,1] = learning_rate_MIN\n",
    "boundaries[1,1] = learning_rate_MAX\n",
    "\n",
    "boundaries_type = [None] * 2\n",
    "boundaries_type[0] = True # Integer\n",
    "boundaries_type[1] = False # Float\n",
    "\n",
    "print(boundaries[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e36f86",
   "metadata": {},
   "source": [
    "# Genetic Algorithm - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c48631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = GeneticAlgorithm(population_size, boundaries, boundaries_type, mutation_rate = 0.6)\n",
    "fm = FileManager()\n",
    "fm.create_file(\"ga_test_mlp_\" + metric)\n",
    "index = 0\n",
    "mlp_ga_ite = []\n",
    "while index < generation:\n",
    "    index += 1\n",
    "    print(\"\\n--- Generation {} ---\".format(index))\n",
    "    ga.generate()  \n",
    "    population = ga.get_population()\n",
    "    for i in population:\n",
    "        start_time = time.time()\n",
    "        parameters = i.get_parameters()\n",
    "        \n",
    "        model = Model(X, Y, model_type = 'MLP', n_neurons = parameters[0], learning_rate = parameters[1])\n",
    "        \n",
    "        fitness_r2 = model.fit_predict_evaluate(n_splits = 3, n_repeats = 5, metric = metric)\n",
    "        \n",
    "        ga.evaluate(i, fitness_r2)\n",
    "        ga_time = time.time() - start_time\n",
    "        fm.write2file([parameters, P, Q, fitness_r2, ga_time])\n",
    "    \n",
    "    mlp_ga_ite.append(ga.get_best_individual().get_fitness())\n",
    "    ga.print_population()\n",
    "    ga.print_best_solution()\n",
    "fm.close_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a377ee",
   "metadata": {},
   "source": [
    "# PSO - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14511c67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables and the population\n",
    "pso = PSO(population_size, boundaries, boundaries_type)\n",
    "fm = FileManager()\n",
    "pop = pso.get_population()\n",
    "fm.create_file(\"pso_test_mlp_\" + metric)\n",
    "mlp_pso_ite = []\n",
    "print('\\nInitializing the population...')\n",
    "for p in pop:\n",
    "    start_time = time.time()\n",
    "    param = p.get_position()\n",
    "\n",
    "    model = Model(X, Y, model_type = 'MLP', n_neurons = int(param[0]), learning_rate = param[1])\n",
    "    fitness_r2 = model.fit_predict_evaluate(n_splits = 3, n_repeats = 5, metric = metric)\n",
    "\n",
    "    pso.insert_particle_fitness(p, fitness_r2)\n",
    "    pso_time = time.time() - start_time\n",
    "    fm.write2file([param, P, Q, fitness_r2, pso_time])\n",
    "\n",
    "pso.print_global_best_particle()\n",
    "\n",
    "iteration = 0\n",
    "print('\\nRunning PSO Loop...')\n",
    "while(iteration < generation):\n",
    "    iteration += 1\n",
    "    print('\\nRunning... : {} of {}.'.format(iteration, generation))\n",
    "    for p in pop:\n",
    "        start_time = time.time()\n",
    "        print(\"Particle {}.\".format(p.get_index()))\n",
    "        pso.calculate_position_velocity(p)\n",
    "        param = p.get_position()\n",
    "        print(param)\n",
    "\n",
    "        model = Model(X, Y, model_type = 'MLP', n_neurons = int(param[0]), learning_rate = param[1])\n",
    "        fitness_r2 = model.fit_predict_evaluate(n_splits = 3, n_repeats = 5, metric = metric)\n",
    "        \n",
    "        pso.insert_particle_fitness(p, fitness_r2)\n",
    "        pso_time = time.time() - start_time\n",
    "        fm.write2file([param, P, Q, fitness_r2, pso_time])\n",
    "        \n",
    "    mlp_pso_ite.append(pso.get_gbest_particle().get_pbest_fitness())\n",
    "    pso.print_global_best_particle()\n",
    "    print(\"GBest_swap = {}\".format(pso.get_best_particle_swap()))\n",
    "    \n",
    "fm.close_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0c0d32",
   "metadata": {},
   "source": [
    "# DT Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9901dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_MAX = 200\n",
    "max_depth_MIN = 10\n",
    "min_samples_split_MAX = 42\n",
    "min_samples_split_MIN = 2\n",
    "\n",
    "boundaries = np.zeros([2,2])\n",
    "boundaries[0,0] = max_depth_MIN\n",
    "boundaries[1,0] = max_depth_MAX\n",
    "boundaries[0,1] = min_samples_split_MIN\n",
    "boundaries[1,1] = min_samples_split_MAX\n",
    "\n",
    "boundaries_type = [None] * 2\n",
    "boundaries_type[0] = True # Integer\n",
    "boundaries_type[1] = True # Integer\n",
    "\n",
    "print(boundaries[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44448f95",
   "metadata": {},
   "source": [
    "# Genetic Algorithm - DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = GeneticAlgorithm(population_size, boundaries, boundaries_type, mutation_rate = 0.5)\n",
    "fm = FileManager()\n",
    "fm.create_file(\"ga_test_dt_\" + metric)\n",
    "index = 0\n",
    "dt_ga_ite = []\n",
    "while index < generation:\n",
    "    index += 1\n",
    "    print(\"\\n--- Generation {} ---\".format(index))\n",
    "    ga.generate()  \n",
    "    population = ga.get_population()\n",
    "    for i in population:\n",
    "        start_time = time.time()\n",
    "        parameters = i.get_parameters()\n",
    "        \n",
    "        model = Model(X, Y, model_type = 'DT', max_depth = parameters[0], min_samples_split = parameters[1])\n",
    "        \n",
    "        fitness_r2 = model.fit_predict_evaluate(n_splits = 3, n_repeats = 5, metric = metric)\n",
    "        \n",
    "        ga.evaluate(i, fitness_r2)\n",
    "        ga_time = time.time() - start_time\n",
    "        fm.write2file([parameters, P, Q, fitness_r2, ga_time])\n",
    "    \n",
    "    dt_ga_ite.append(ga.get_best_individual().get_fitness())\n",
    "    ga.print_population()\n",
    "    ga.print_best_solution()\n",
    "fm.close_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bf9dbb",
   "metadata": {},
   "source": [
    "# PSO - DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5977f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables and the population\n",
    "pso = PSO(population_size, boundaries, boundaries_type)\n",
    "fm = FileManager()\n",
    "pop = pso.get_population()\n",
    "fm.create_file(\"pso_test_dt_\" + metric)\n",
    "dt_pso_ite = []\n",
    "print('\\nInitializing the population...')\n",
    "for p in pop:\n",
    "    start_time = time.time()\n",
    "    param = p.get_position()\n",
    "    print(param)\n",
    "    model = Model(X, Y, model_type = 'DT', max_depth = int(param[0]), min_samples_split = int(param[1]))\n",
    "    fitness_r2 = model.fit_predict_evaluate(n_splits = 3, n_repeats = 5, metric = metric)\n",
    "\n",
    "    pso.insert_particle_fitness(p, fitness_r2)\n",
    "    pso_time = time.time() - start_time\n",
    "    fm.write2file([param, P, Q, fitness_r2, pso_time])\n",
    "\n",
    "pso.print_global_best_particle()\n",
    "\n",
    "iteration = 0\n",
    "print('\\nRunning PSO Loop...')\n",
    "while(iteration < generation):\n",
    "    iteration += 1\n",
    "    print('\\nRunning... : {} of {}.'.format(iteration, generation))\n",
    "    for p in pop:\n",
    "        start_time = time.time()\n",
    "        print(\"Particle {}.\".format(p.get_index()))\n",
    "        pso.calculate_position_velocity(p)\n",
    "        param = p.get_position()\n",
    "        print(param)\n",
    "\n",
    "        model = Model(X, Y, model_type = 'DT', max_depth = int(param[0]), min_samples_split = int(param[1]))\n",
    "        fitness_r2 = model.fit_predict_evaluate(n_splits = 3, n_repeats = 5, metric = metric)\n",
    "        \n",
    "        pso.insert_particle_fitness(p, fitness_r2)\n",
    "        pso_time = time.time() - start_time\n",
    "        fm.write2file([param, P, Q, fitness_r2, pso_time])\n",
    "        \n",
    "    dt_pso_ite.append(pso.get_gbest_particle().get_pbest_fitness())\n",
    "    pso.print_global_best_particle()\n",
    "    print(\"GBest_swap = {}\".format(pso.get_best_particle_swap()))\n",
    "    \n",
    "fm.close_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96a6fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_ga_ite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c22cab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4794c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1, len(dt_ga_ite) + 1)]\n",
    "data_preproc = pd.DataFrame({\n",
    "    'x': x, \n",
    "    'GA-MLP': mlp_ga_ite,\n",
    "    'PSO-MLP': mlp_pso_ite,\n",
    "    'GA-DT': dt_ga_ite,\n",
    "    'PSO-DT': dt_pso_ite})\n",
    "\n",
    "plt.figure()\n",
    "fontsize = 20\n",
    "ax = sns.lineplot(x='x', y='value', hue='variable', data=pd.melt(data_preproc, ['x']), marker = 'o')\n",
    "ax.set(xticks=data_preproc['x'])\n",
    "plt.xlabel(\"Iteration\", fontsize = fontsize)\n",
    "plt.ylabel(\"Average \" + metric, fontsize = fontsize)\n",
    "plt.title(\"PSO and GA Comparison - MLP\", fontsize = fontsize)\n",
    "plt.legend(prop={'size': 16})\n",
    "plt.tight_layout()\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "plt.savefig('gapsomlp_' + metric + '.png', dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d1bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1, len(dt_ga_ite) + 1)]\n",
    "ax = plt.figure().gca()\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.plot(x, dt_ga_ite, color = 'r', label = 'GA-DT')\n",
    "plt.plot(x, dt_pso_ite, color = 'b', label = 'PSO-DT')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Average R² \")\n",
    "plt.title(\"PSO and GA Comparison - DT\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('gapsodt.png', dpi = 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c198e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in l_ru:\n",
    "    df_test = dfx[dfx['radio_id'] == i]\n",
    "    pp = Preprocessing(df_test)\n",
    "    X, Y = pp.get_data()\n",
    "    \n",
    "    model = Model(X, Y, model_type = 'MLP', max_depth = 200, min_samples_split = 0.00005)\n",
    "    fitness_r2 = model.fit_predict_evaluate(n_splits = 3, n_repeats = 5, metric = 'r2')\n",
    "    print('radio_id: {} max: {} min: {}, metric: {}'.format(i, max(pp.get_dataframe()['count']), min(pp.get_dataframe()['count']) , fitness_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c9ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 'iad-2andar'\n",
    "df_test = dfx[dfx['radio_id'] == i]\n",
    "pp = Preprocessing(df_test)\n",
    "X, Y = pp.get_data()\n",
    "\n",
    "model = Model(X, Y, model_type = 'MLP', max_depth = 200, min_samples_split = 0.00005)\n",
    "fitness_r2 = model.fit_predict_evaluate(n_splits = 3, n_repeats = 5, metric = 'r2')\n",
    "print('radio_id: {} max: {} min: {}, metric: {}'.format(i, max(pp.get_dataframe()['count']), min(pp.get_dataframe()['count']) , fitness_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9176932",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 'iad-1andar'\n",
    "df_test = dfx[dfx['radio_id'] == i]\n",
    "pp = Preprocessing(df_test)\n",
    "X, Y = pp.get_data()\n",
    "\n",
    "model = Model(X, Y, model_type = 'MLP', max_depth = 200, min_samples_split = 0.00005)\n",
    "fitness_r2 = model.fit_predict_evaluate(n_splits = 3, n_repeats = 5, metric = 'r2')\n",
    "print('radio_id: {} max: {} min: {}, metric: {}'.format(i, max(pp.get_dataframe()['count']), min(pp.get_dataframe()['count']) , fitness_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c912fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 'ap4600-67afac'\n",
    "df_test = dfx[dfx['radio_id'] == i]\n",
    "pp = Preprocessing(df_test)\n",
    "X, Y = pp.get_data()\n",
    "\n",
    "model = Model(X, Y, model_type = 'MLP', max_depth = 200, min_samples_split = 0.00005)\n",
    "fitness_r2 = model.fit_predict_evaluate(n_splits = 3, n_repeats = 5, metric = 'r2')\n",
    "print('radio_id: {} max: {} min: {}, metric: {}'.format(i, max(pp.get_dataframe()['count']), min(pp.get_dataframe()['count']) , fitness_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ac24d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 'anfiteatro'\n",
    "df_test = dfx[dfx['radio_id'] == i]\n",
    "pp = Preprocessing(df_test)\n",
    "X, Y = pp.get_data()\n",
    "\n",
    "model = Model(X, Y, model_type = 'MLP', max_depth = 200, min_samples_split = 0.00005)\n",
    "fitness_r2 = model.fit_predict_evaluate(n_splits = 3, n_repeats = 5, metric = 'r2')\n",
    "print('radio_id: {} max: {} min: {}, metric: {}'.format(i, max(pp.get_dataframe()['count']), min(pp.get_dataframe()['count']) , fitness_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eaf4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = pd.read_csv(\"../ufjf_dataset.csv\")\n",
    "dftest.rename(columns={'time1': 'timestamp', 'timet': 'connection_time', 'client_id': 'host', 'radio_id': 'access_point'}, inplace=True)\n",
    "dftest.to_csv('ufjf_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aec245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = '.'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "onlyfiles = [i for i in onlyfiles if i.endswith('_best.csv')]\n",
    "onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094cfb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in onlyfiles:\n",
    "    df_plot = pd.read_csv(i)\n",
    "    metric_used = i[:-9]\n",
    "    sns.set(rc = {'figure.figsize':(20,8)})\n",
    "    x = [i for i in range(1,11)]\n",
    "    data_preproc = pd.DataFrame({\n",
    "        'x': x,\n",
    "        'GA-MLP': list(df_plot[df_plot['Opt'] == 'GA'][df_plot['Model'] == 'MLP']['Best_fitness']),\n",
    "        'PSO-MLP': list(df_plot[df_plot['Opt'] == 'PSO'][df_plot['Model'] == 'MLP']['Best_fitness']),\n",
    "        'GA-DT': list(df_plot[df_plot['Opt'] == 'GA'][df_plot['Model'] == 'DT']['Best_fitness']),\n",
    "        'PSO-DT': list(df_plot[df_plot['Opt'] == 'PSO'][df_plot['Model'] == 'DT']['Best_fitness'])})\n",
    "\n",
    "    plt.figure()\n",
    "    print(metric_used)\n",
    "    print(data_preproc.min())\n",
    "    print(data_preproc.max())\n",
    "    if(metric_used == 'r2'):\n",
    "        metric_used = 'r²'\n",
    "    fontsize = 44\n",
    "    ax = sns.lineplot(x='x', y='value', hue='variable', data=pd.melt(data_preproc, ['x']), marker = 'o', linewidth=4)\n",
    "    ax.set(xticks=data_preproc['x'])\n",
    "    plt.xlabel(\"Iteração\", fontsize = fontsize)\n",
    "    plt.ylabel(metric_used.upper() + \" Médio\", fontsize = fontsize)\n",
    "    #plt.title(\"PSO and GA Comparison - MLP and DT\", fontsize = fontsize)\n",
    "    leg = plt.legend(prop={'size': 38})\n",
    "    leg_lines = leg.get_lines()\n",
    "    plt.xticks(fontsize = fontsize)\n",
    "    plt.yticks(fontsize = fontsize)\n",
    "    plt.setp(leg_lines, linewidth=6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(metric_used + '_gapsomlpdt.png', dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2c5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "n = 300\n",
    "#X = np.reshape(X,(X.shape[0], 1, X.shape[1]))\n",
    "shape = X.shape[1:]\n",
    "early_stopping_monitor = EarlyStopping(monitor='loss',patience=2)\n",
    "kf = RepeatedKFold(n_splits=3, n_repeats=5)\n",
    "score = []\n",
    "epochs = 1000\n",
    "n_batch = 64\n",
    "i = 0\n",
    "start_time = time.time()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    i += 1\n",
    "    print(i)\n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(n, input_shape = shape, return_sequences = False, kernel_initializer = 'normal'))#, activation = cf\n",
    "    model.add(Dense(units = 1, activation = 'sigmoid', kernel_initializer = 'normal'))#return_sequences = False\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    model.fit(x_train, y_train, epochs = epochs, batch_size = n_batch, verbose = 0, callbacks=[early_stopping_monitor])\n",
    "    predicted = model.predict(x_test)\n",
    "    \n",
    "    score.append(r2_score(y_test, predicted))\n",
    "    \n",
    "final_time = time.time()\n",
    "print(final_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b73b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f7d5ee",
   "metadata": {},
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba0f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "print(joblib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3b967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'r2ga_mlp.sat'\n",
    "model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1125edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfx = pd.read_csv(\"../ufjf_dataset.csv\")\n",
    "dfx = pd.read_csv(\"../ufjf_dataset_cleaned.csv\")\n",
    "dfx['timestamp'] = pd.to_datetime(dfx['timestamp'])\n",
    "dfx.index = dfx['timestamp']\n",
    "dfx['access_point'] = dfx['access_point'].str.lower()\n",
    "\n",
    "dfxx = dfx[dfx['access_point'].str.contains('ru')]\n",
    "l_ru = list(dfxx['access_point'].unique())\n",
    "print(l_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e045094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f151ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfx[dfx['access_point'].str.contains('|'.join(l_ru))]\n",
    "# df = dfx[dfx['access_point'] == 'iad-2andar']\n",
    "pp = Preprocessing(df)\n",
    "X, Y = pp.get_data()\n",
    "\n",
    "kf = RepeatedKFold(n_splits=3, n_repeats=5)\n",
    "score = []\n",
    "best_metric = 0\n",
    "best_y_test = None\n",
    "best_predicted = None\n",
    "for train_index, test_index in kf.split(X):\n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    predicted = model.predict(x_test)\n",
    "    metric = r2_score(y_test, predicted)\n",
    "    score.append(metric)\n",
    "    if(best_metric < metric):\n",
    "        best_metric = metric\n",
    "        best_y_test = y_test\n",
    "        best_predicted = predicted\n",
    "        \n",
    "    \n",
    "print('%.4f +- %.4f' % (np.mean(score), np.std(score)))\n",
    "plt.scatter(best_predicted, best_y_test)\n",
    "plt.plot([0.0,0.9],[0.0,0.9], color = 'r')\n",
    "plt.xlabel(\"Number of Predicted Users\")\n",
    "plt.ylabel(\"Number of Real Users\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('predxreal.png', dpi = 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744c0673",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = pp.get_max_value()\n",
    "min_value = pp.get_min_value()\n",
    "ap_threshold = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c19b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_back(value, max_value, min_value):\n",
    "    return int((max_value - min_value) * value)\n",
    "\n",
    "def convert_number_AP(value, threshold):\n",
    "    return int(value / threshold) + 1\n",
    "\n",
    "best_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bde3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predicted_test = [convert_back(value, max_value, min_value) for value in best_predicted]\n",
    "predicted_number_ap = [convert_number_AP(value, ap_threshold) for value in best_predicted_test]\n",
    "x = [i for i in range(len(predicted_number_ap))]\n",
    "df_plot = pd.DataFrame(predicted_number_ap, columns = ['Number_Allocated_AP'])\n",
    "df_plot = df_plot['Number_Allocated_AP'].value_counts().to_frame()\n",
    "df_plot['type'] = 'Predito'\n",
    "\n",
    "best_y_test1 = [convert_back(value, max_value, min_value) for value in best_y_test]\n",
    "real_number_ap = [convert_number_AP(value, ap_threshold) for value in best_y_test1]\n",
    "x = [i for i in range(len(real_number_ap))]\n",
    "df_plot1 = pd.DataFrame(real_number_ap, columns = ['Number_Allocated_AP'])\n",
    "df_plot1 = df_plot1['Number_Allocated_AP'].value_counts().to_frame()\n",
    "df_plot1['type'] = 'Real'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7fe312",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_plot, df_plot1]\n",
    "  \n",
    "result = pd.concat(frames)\n",
    "result['APx'] = result.index\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cdc889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "#sns.set(rc = {'figure.figsize':(20,8)})\n",
    "\n",
    "hit = 0\n",
    "total = len(real_number_ap)\n",
    "for i in range(len(predicted_number_ap)):\n",
    "    if predicted_number_ap[i] == real_number_ap[i]:\n",
    "        hit += 1\n",
    "        \n",
    "print('%.2f%%' % ((hit / total) * 100))\n",
    "\n",
    "sns.set(rc = {'figure.figsize':(20,8)})\n",
    "test_predict = collections.Counter(predicted_number_ap)\n",
    "test_predict = list(test_predict.values())\n",
    "test_predict_pctg = [round(((i / total) * 100),2) for i in test_predict]\n",
    "\n",
    "test_real = collections.Counter(real_number_ap)\n",
    "test_real = list(test_real.values())\n",
    "test_real_pctg = [round(((i / total) * 100),2) for i in test_real]\n",
    "\n",
    "fontsize = 28\n",
    "ax = plt.figure().gca()\n",
    "#bar1 = plt.bar(np.arange(len(errorRateListOfFast)) + bar_width, errorRateListOfFast, bar_width, align='center', alpha=opacity, color='b', label='Fast <= 6 sec.')\n",
    "#plt.hist(df_plot['Number_Allocated_AP'], bins=bins) #color = 'white', edgecolor='black', hatch=['x', '\\\\', '//', '/'])\n",
    "\n",
    "sns.barplot(x='APx',y='Number_Allocated_AP',data = result,hue = 'type', edgecolor='black')\n",
    "#result['Number_Allocated_AP'].value_counts().plot.bar(edgecolor = 'black', label = 'test', y=[\"Predicted\", \"True\"])\n",
    "#ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.xlabel('Número de Pontos de Acesso Alocados', fontsize = fontsize)\n",
    "plt.ylabel('Número de Predições', fontsize = fontsize)\n",
    "plt.xticks(fontsize = fontsize, rotation = 0)\n",
    "plt.yticks(fontsize = fontsize)\n",
    "for i, v in enumerate(test_predict):\n",
    "    ax.text(i - 0.2, v, str(v) + ' - ' + str(test_predict_pctg[i]) +'%', color='black', fontsize = 20, ha='center', va='bottom')\n",
    "    \n",
    "for i, v in enumerate(test_real):\n",
    "    ax.text(i + 0.2, v, str(v) + ' - ' + str(test_real_pctg[i]) +'%', color='black', fontsize = 20, ha='center', va='bottom')\n",
    "\n",
    "leg = plt.legend(prop={'size': fontsize})\n",
    "leg_lines = leg.get_lines()\n",
    "plt.tight_layout()\n",
    "plt.savefig('barplot.png', dpi = 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6520048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_y_test1 = [convert_back(value, max_value, min_value) for value in best_y_test]\n",
    "real_number_ap = [convert_number_AP(value, ap_threshold) for value in best_y_test1]\n",
    "x = [i for i in range(len(real_number_ap))]\n",
    "df_plot = pd.DataFrame(real_number_ap, columns = ['Number_Allocated_AP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d57426",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = collections.Counter(real_number_ap)\n",
    "test = list(test.values())\n",
    "\n",
    "fontsize = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586b0100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "labels = df_plot['Number_Allocated_AP'].unique()\n",
    "df_cm = confusion_matrix(real_number_ap, predicted_number_ap)\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True, xticklabels=labels, yticklabels=labels, fmt='g', annot_kws={\"fontsize\": fontsize})\n",
    "plt.xlabel(\"Predito\", fontsize = fontsize)\n",
    "plt.ylabel(\"Real\", fontsize = fontsize)\n",
    "plt.xticks(fontsize = fontsize)\n",
    "plt.yticks(fontsize = fontsize)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Conf_Mat.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01173766",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = pd.read_csv('ga_test_mlp_r2.csv')\n",
    "dftest_aux = dftest[dftest['Param02'] == max(dftest['Param02'])]\n",
    "dftest_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d1509",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = pd.read_csv('ga_test_dt_r2.csv')\n",
    "dftest_aux = dftest[dftest['Param02'] == max(dftest['Param02'])]\n",
    "dftest_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04536033",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = pd.read_csv('pso_test_dt_r2.csv')\n",
    "dftest_aux = dftest[dftest['Param02'] == max(dftest['Param02'])]\n",
    "dftest_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ddbf06",
   "metadata": {},
   "source": [
    "# Testing DT criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0d80ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = []\n",
    "\n",
    "model = Model(X, Y, model_type = 'DT', max_depth = None, min_samples_split = 40)\n",
    "model2 = Model(X, Y, model_type = 'DT', max_depth = None, min_samples_split = 40, criterion = 'squared_error')\n",
    "model3 = Model(X, Y, model_type = 'DT', max_depth = None, min_samples_split = 40, criterion = 'absolute_error')\n",
    "model4 = Model(X, Y, model_type = 'DT', max_depth = None, min_samples_split = 40, criterion = 'poisson')\n",
    "\n",
    "fitness_r2 = model.fit_predict_evaluate(n_splits = 3, n_repeats = 3, metric = metric)\n",
    "fitness_r22 = model2.fit_predict_evaluate(n_splits = 3, n_repeats = 3, metric = metric)\n",
    "fitness_r23 = model3.fit_predict_evaluate(n_splits = 3, n_repeats = 3, metric = metric)\n",
    "fitness_r24 = model4.fit_predict_evaluate(n_splits = 3, n_repeats = 3, metric = metric)\n",
    "print(\"R2 usado: {}\".format(fitness_r2))\n",
    "print(\"R2 square: {}\".format(fitness_r2))\n",
    "print(\"R2 absolute: {}\".format(fitness_r2))\n",
    "print(\"R2 poisson: {}\".format(fitness_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de9634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
